{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6423dc80",
   "metadata": {},
   "source": [
    "## 1. Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des packages n√©cessaires\n",
    "!pip install gymnasium stable-baselines3[extra] torch numpy matplotlib tensorboard -q\n",
    "print(\"‚úÖ Installation termin√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd9483",
   "metadata": {},
   "source": [
    "## 2. D√©finition de l'environnement Snake (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import pygame\n",
    "\n",
    "# M√™mes constantes qu'avant\n",
    "WINDOW_WIDTH = 600\n",
    "WINDOW_HEIGHT = 600\n",
    "BLOCK_SIZE = 20\n",
    "SPEED = 20\n",
    "\n",
    "# Couleurs modernes\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (15, 15, 25)\n",
    "DARK_GRAY = (30, 30, 40)\n",
    "RED = (255, 80, 80)\n",
    "ORANGE = (255, 165, 0)\n",
    "GREEN = (76, 175, 80)\n",
    "BLUE1 = (66, 165, 245)\n",
    "BLUE2 = (33, 150, 243)\n",
    "CYAN = (0, 188, 212)\n",
    "YELLOW = (255, 235, 59)\n",
    "\n",
    "class SnakeEnvCnn(gym.Env):\n",
    "    metadata = {'render_modes': ['human'], 'render_fps': SPEED}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        super(SnakeEnvCnn, self).__init__()\n",
    "        self.w = WINDOW_WIDTH\n",
    "        self.h = WINDOW_HEIGHT\n",
    "        self.render_mode = render_mode\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        self.font = None\n",
    "        self.small_font = None\n",
    "        \n",
    "        # Calcul du nombre de cases (ex: 30x30)\n",
    "        self.grid_w = int(self.w / BLOCK_SIZE)\n",
    "        self.grid_h = int(self.h / BLOCK_SIZE)\n",
    "\n",
    "        # ACTION : inchang√©\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # OBSERVATION : C'est l√† que tout change !\n",
    "        # On renvoie une \"Image\" de taille (1, 30, 30) (1 canal, Hauteur, Largeur)\n",
    "        # Valeurs : 0=Vide, 80=Corps, 180=T√™te, 255=Pomme (Nuances de gris)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=255, \n",
    "            shape=(1, self.grid_h, self.grid_w), \n",
    "            dtype=np.uint8\n",
    "        )\n",
    "        \n",
    "        # Pour le reward shaping\n",
    "        self.prev_distance = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.direction = 1\n",
    "        self.head = [self.w/2, self.h/2]\n",
    "        self.snake = [self.head, \n",
    "                      [self.head[0]-BLOCK_SIZE, self.head[1]],\n",
    "                      [self.head[0]-(2*BLOCK_SIZE), self.head[1]]]\n",
    "        self.score = 0\n",
    "        self.frame_iteration = 0\n",
    "        self._place_food()\n",
    "        self.prev_distance = self._get_distance()\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def _get_distance(self):\n",
    "        \"\"\"Distance de Manhattan entre la t√™te et la pomme\"\"\"\n",
    "        return abs(self.head[0] - self.food[0]) + abs(self.head[1] - self.food[1])\n",
    "\n",
    "    def step(self, action):\n",
    "        self.frame_iteration += 1\n",
    "        self._move(action)\n",
    "        \n",
    "        game_over = False\n",
    "        reward = 0\n",
    "        \n",
    "        # Collision = Game Over\n",
    "        if self._is_collision() or self.frame_iteration > 100*len(self.snake):\n",
    "            game_over = True\n",
    "            reward = -10\n",
    "            return self._get_observation(), reward, game_over, False, {}\n",
    "        \n",
    "        # Calculer la nouvelle distance\n",
    "        new_distance = self._get_distance()\n",
    "        \n",
    "        # Manger la pomme = grosse r√©compense\n",
    "        if self.head == self.food:\n",
    "            self.score += 1\n",
    "            reward = 20  # Augment√© de 10 √† 20\n",
    "            self._place_food()\n",
    "            self.prev_distance = self._get_distance()\n",
    "        else:\n",
    "            self.snake.pop()\n",
    "            \n",
    "            # REWARD SHAPING : R√©compense/punition bas√©e sur la distance\n",
    "            # Se rapprocher = +1, s'√©loigner = -1\n",
    "            if new_distance < self.prev_distance:\n",
    "                reward = 1  # Se rapproche de la pomme\n",
    "            elif new_distance > self.prev_distance:\n",
    "                reward = -1  # S'√©loigne de la pomme\n",
    "            # Sinon reward = 0 (m√™me distance)\n",
    "            \n",
    "            self.prev_distance = new_distance\n",
    "            \n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "            \n",
    "        return self._get_observation(), reward, game_over, False, {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        # On cr√©e une grille vide (Fond noir = 0)\n",
    "        grid = np.zeros((self.grid_h, self.grid_w), dtype=np.uint8)\n",
    "        \n",
    "        # On dessine le corps (Gris fonc√© = 80)\n",
    "        for pt in self.snake:\n",
    "            x = int(pt[0] / BLOCK_SIZE)\n",
    "            y = int(pt[1] / BLOCK_SIZE)\n",
    "            if 0 <= x < self.grid_w and 0 <= y < self.grid_h:\n",
    "                grid[y, x] = 80\n",
    "        \n",
    "        # On dessine la t√™te (Gris clair = 180) pour qu'il sache o√π il est\n",
    "        hx = int(self.head[0] / BLOCK_SIZE)\n",
    "        hy = int(self.head[1] / BLOCK_SIZE)\n",
    "        if 0 <= hx < self.grid_w and 0 <= hy < self.grid_h:\n",
    "            grid[hy, hx] = 180\n",
    "            \n",
    "        # On dessine la pomme (Blanc = 255)\n",
    "        fx = int(self.food[0] / BLOCK_SIZE)\n",
    "        fy = int(self.food[1] / BLOCK_SIZE)\n",
    "        grid[fy, fx] = 255\n",
    "        \n",
    "        # On ajoute la dimension du canal (1, 30, 30) exig√©e par PyTorch CNN\n",
    "        return np.expand_dims(grid, axis=0)\n",
    "\n",
    "    # ... Les m√©thodes _place_food, _is_collision, _move, _render_frame sont identiques √† V1 ...\n",
    "    # (Copiez-les depuis snake_env.py, elles ne changent pas)\n",
    "    def _place_food(self):\n",
    "        x = random.randint(0, (self.w-BLOCK_SIZE )//BLOCK_SIZE )*BLOCK_SIZE \n",
    "        y = random.randint(0, (self.h-BLOCK_SIZE )//BLOCK_SIZE )*BLOCK_SIZE\n",
    "        self.food = [x, y]\n",
    "        if self.food in self.snake: self._place_food()\n",
    "\n",
    "    def _is_collision(self, pt=None):\n",
    "        if pt is None: pt = self.head\n",
    "        if pt[0] > self.w - BLOCK_SIZE or pt[0] < 0 or pt[1] > self.h - BLOCK_SIZE or pt[1] < 0: return True\n",
    "        if pt in self.snake[1:]: return True\n",
    "        return False\n",
    "\n",
    "    def _move(self, action):\n",
    "        clock_wise = [0, 1, 2, 3]\n",
    "        if action == 0 and self.direction != 1: self.direction = 0\n",
    "        elif action == 1 and self.direction != 0: self.direction = 1\n",
    "        elif action == 2 and self.direction != 3: self.direction = 2\n",
    "        elif action == 3 and self.direction != 2: self.direction = 3\n",
    "        x = self.head[0]\n",
    "        y = self.head[1]\n",
    "        if self.direction == 1: x += BLOCK_SIZE\n",
    "        elif self.direction == 0: x -= BLOCK_SIZE\n",
    "        elif self.direction == 3: y += BLOCK_SIZE\n",
    "        elif self.direction == 2: y -= BLOCK_SIZE\n",
    "        self.head = [x, y]\n",
    "        self.snake.insert(0, self.head)\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.window is None:\n",
    "            pygame.init()\n",
    "            self.window = pygame.display.set_mode((self.w, self.h))\n",
    "            self.clock = pygame.time.Clock()\n",
    "            self.font = pygame.font.Font(None, 48)\n",
    "            self.small_font = pygame.font.Font(None, 32)\n",
    "            pygame.display.set_caption(\"üêç Snake AI CNN Training üêç\")\n",
    "        \n",
    "        # Fond\n",
    "        self.window.fill(BLACK)\n",
    "        \n",
    "        # Grille l√©g√®re en arri√®re-plan\n",
    "        grid_color = (50, 50, 70)\n",
    "        for x in range(0, self.w, BLOCK_SIZE):\n",
    "            pygame.draw.line(self.window, grid_color, (x, 0), (x, self.h), 1)\n",
    "        for y in range(0, self.h, BLOCK_SIZE):\n",
    "            pygame.draw.line(self.window, grid_color, (0, y), (self.w, y), 1)\n",
    "            \n",
    "        # Dessiner la Pomme\n",
    "        self._draw_apple()\n",
    "        \n",
    "        # Dessiner le Serpent\n",
    "        self._draw_snake()\n",
    "        \n",
    "        # Afficher le Score\n",
    "        self._draw_score()\n",
    "        \n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(self.metadata[\"render_fps\"])\n",
    "\n",
    "    def _draw_apple(self):\n",
    "        \"\"\"Dessiner la pomme avec un effet visuel am√©lior√©\"\"\"\n",
    "        x, y = int(self.food[0]), int(self.food[1])\n",
    "        \n",
    "        # Lueur autour de la pomme\n",
    "        glow_radius = BLOCK_SIZE // 2 + 3\n",
    "        pygame.draw.circle(self.window, (255, 100, 0, 50), (x + BLOCK_SIZE//2, y + BLOCK_SIZE//2), glow_radius)\n",
    "        \n",
    "        # Pomme principale (d√©grad√© simul√©)\n",
    "        pygame.draw.rect(self.window, RED, pygame.Rect(x+2, y+2, BLOCK_SIZE-4, BLOCK_SIZE-4), border_radius=4)\n",
    "        pygame.draw.rect(self.window, ORANGE, pygame.Rect(x+3, y+3, BLOCK_SIZE-6, BLOCK_SIZE-6), border_radius=3)\n",
    "        \n",
    "        # Brillance\n",
    "        pygame.draw.circle(self.window, YELLOW, (x + 7, y + 7), 3)\n",
    "\n",
    "    def _draw_snake(self):\n",
    "        \"\"\"Dessiner le serpent avec d√©grad√© de couleur\"\"\"\n",
    "        snake_length = len(self.snake)\n",
    "        \n",
    "        for i, pt in enumerate(self.snake):\n",
    "            x, y = int(pt[0]), int(pt[1])\n",
    "            \n",
    "            # Couleur d√©grad√©e : cyan pour la t√™te, bleu pour la queue\n",
    "            ratio = i / max(snake_length - 1, 1)\n",
    "            color = (\n",
    "                int(BLUE1[0] + (CYAN[0] - BLUE1[0]) * (1 - ratio)),\n",
    "                int(BLUE1[1] + (CYAN[1] - BLUE1[1]) * (1 - ratio)),\n",
    "                int(BLUE1[2] + (CYAN[2] - BLUE1[2]) * (1 - ratio))\n",
    "            )\n",
    "            \n",
    "            # Corps du serpent (arrondi pour plus joli)\n",
    "            pygame.draw.rect(self.window, color, pygame.Rect(x+1, y+1, BLOCK_SIZE-2, BLOCK_SIZE-2), border_radius=3)\n",
    "            \n",
    "            # T√™te du serpent (plus grande et brillante)\n",
    "            if i == 0:\n",
    "                pygame.draw.rect(self.window, CYAN, pygame.Rect(x, y, BLOCK_SIZE, BLOCK_SIZE), border_radius=4)\n",
    "                pygame.draw.circle(self.window, WHITE, (x + 6, y + 6), 2)\n",
    "                pygame.draw.circle(self.window, WHITE, (x + 14, y + 6), 2)\n",
    "\n",
    "    def _draw_score(self):\n",
    "        \"\"\"Afficher le score et les informations en haut √† droite\"\"\"\n",
    "        score_text = self.font.render(f\"Score: {self.score}\", True, GREEN)\n",
    "        length_text = self.small_font.render(f\"Length: {len(self.snake)}\", True, CYAN)\n",
    "        frame_text = self.small_font.render(f\"Frame: {self.frame_iteration}\", True, WHITE)\n",
    "        \n",
    "        # Position en haut √† droite\n",
    "        panel_width = 180\n",
    "        panel_x = self.w - panel_width - 10\n",
    "        \n",
    "        # Fond semi-transparent pour la lisibilit√©\n",
    "        pygame.draw.rect(self.window, DARK_GRAY, (panel_x, 5, panel_width, 90), border_radius=5)\n",
    "        pygame.draw.rect(self.window, CYAN, (panel_x, 5, panel_width, 90), 2, border_radius=5)\n",
    "        \n",
    "        self.window.blit(score_text, (panel_x + 10, 10))\n",
    "        self.window.blit(length_text, (panel_x + 10, 45))\n",
    "        self.window.blit(frame_text, (panel_x + 10, 70))\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220c073",
   "metadata": {},
   "source": [
    "## 3. üß† D√©finition du r√©seau CNN personnalis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    R√©seau de neurones convolutif pour traiter la grille 30x30.\n",
    "    Architecture :\n",
    "    - Conv2D (32 filtres, 4x4) -> ReLU\n",
    "    - Conv2D (64 filtres, 4x4) -> ReLU\n",
    "    - Flatten -> Linear (256) -> ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 256):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 32, kernel_size=4, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        # Calcul automatique de la taille apr√®s convolutions\n",
    "        with th.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                th.as_tensor(observation_space.sample()[None]).float()\n",
    "            ).shape[1]\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(n_flatten, features_dim), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        return self.linear(self.cnn(observations))\n",
    "\n",
    "print(\"‚úÖ CustomCNN d√©fini !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0238b",
   "metadata": {},
   "source": [
    "## 4. ‚öôÔ∏è Configuration de l'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "N_ENVS = 8           # Nombre d'environnements parall√®les (Colab a ~2 CPUs, mais √ßa marche)\n",
    "TIMESTEPS = 2_000_000  # Nombre total de steps (augmenter pour de meilleurs r√©sultats)\n",
    "SAVE_FREQ = 100_000   # Sauvegarder tous les X steps\n",
    "\n",
    "# Dossiers\n",
    "MODELS_DIR = \"checkpoints/PPO_CNN_COLAB\"\n",
    "LOG_DIR = \"logs\"\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìä Configuration :\")\n",
    "print(f\"   - Environnements parall√®les : {N_ENVS}\")\n",
    "print(f\"   - Steps totaux : {TIMESTEPS:,}\")\n",
    "print(f\"   - Sauvegarde tous les : {SAVE_FREQ:,} steps\")\n",
    "print(f\"   - Dossier mod√®les : {MODELS_DIR}\")\n",
    "print(f\"   - Dossier logs : {LOG_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13952f4",
   "metadata": {},
   "source": [
    "## 5. üöÄ Lancement de l'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier le GPU\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üñ•Ô∏è Device utilis√© : {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU : {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Cr√©ation des environnements vectoris√©s\n",
    "print(f\"\\nüîÑ Cr√©ation de {N_ENVS} environnements parall√®les...\")\n",
    "env = make_vec_env(\n",
    "    SnakeEnvCnn, \n",
    "    n_envs=N_ENVS,\n",
    "    vec_env_cls=SubprocVecEnv\n",
    ")\n",
    "\n",
    "# Callback pour sauvegarder r√©guli√®rement\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=max(SAVE_FREQ // N_ENVS, 1),\n",
    "    save_path=MODELS_DIR,\n",
    "    name_prefix=\"snake_cnn\"\n",
    ")\n",
    "\n",
    "# Configuration du CNN\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=256),\n",
    ")\n",
    "\n",
    "# Cr√©ation du mod√®le PPO\n",
    "print(\"üß† Cr√©ation du mod√®le PPO avec CNN...\")\n",
    "model = PPO(\n",
    "    \"CnnPolicy\", \n",
    "    env, \n",
    "    verbose=1, \n",
    "    tensorboard_log=LOG_DIR,\n",
    "    learning_rate=0.0003,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    batch_size=256,\n",
    "    n_steps=1024,\n",
    "    gamma=0.99,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéÆ D√âMARRAGE DE L'ENTRA√éNEMENT\")\n",
    "print(\"=\"*50)\n",
    "print(f\"L'IA va jouer {TIMESTEPS:,} coups...\")\n",
    "print(\"Cela peut prendre 30min √† 2h selon la configuration.\")\n",
    "print(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancement de l'entra√Ænement\n",
    "model.learn(\n",
    "    total_timesteps=TIMESTEPS, \n",
    "    callback=checkpoint_callback,\n",
    "    progress_bar=True  # Barre de progression\n",
    ")\n",
    "\n",
    "# Sauvegarde finale\n",
    "final_path = f\"{MODELS_DIR}/snake_cnn_final\"\n",
    "model.save(final_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ ENTRA√éNEMENT TERMIN√â !\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Mod√®le final sauvegard√© : {final_path}.zip\")\n",
    "\n",
    "# Fermer les environnements\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d6830",
   "metadata": {},
   "source": [
    "## 6. üìà Visualisation des logs TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb75645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger TensorBoard dans le notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6bfacb",
   "metadata": {},
   "source": [
    "## 7. üì• T√©l√©charger le mod√®le entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister les mod√®les sauvegard√©s\n",
    "import glob\n",
    "\n",
    "models = glob.glob(f\"{MODELS_DIR}/*.zip\")\n",
    "models.sort()\n",
    "\n",
    "print(\"üìÅ Mod√®les disponibles :\")\n",
    "for i, m in enumerate(models):\n",
    "    print(f\"   [{i}] {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161657ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©l√©charger le mod√®le final\n",
    "from google.colab import files\n",
    "\n",
    "# T√©l√©charge le dernier mod√®le\n",
    "if models:\n",
    "    files.download(models[-1])\n",
    "    print(f\"\\nüì• T√©l√©chargement de : {models[-1]}\")\n",
    "else:\n",
    "    print(\"‚ùå Aucun mod√®le trouv√© !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionnel : Cr√©er une archive de tous les checkpoints\n",
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"snake_models\", 'zip', MODELS_DIR)\n",
    "files.download(\"snake_models.zip\")\n",
    "print(\"üì• Archive de tous les mod√®les t√©l√©charg√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810b93f",
   "metadata": {},
   "source": [
    "## 8. üß™ Test rapide du mod√®le (sans rendu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et tester le mod√®le\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Charger le meilleur mod√®le\n",
    "test_model = PPO.load(f\"{MODELS_DIR}/snake_cnn_final\")\n",
    "\n",
    "# Cr√©er un environnement de test\n",
    "test_env = SnakeEnvCnn()\n",
    "\n",
    "# Jouer 10 parties\n",
    "scores = []\n",
    "for episode in range(10):\n",
    "    obs, _ = test_env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = test_model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = test_env.step(action)\n",
    "        if reward > 0:\n",
    "            score += 1\n",
    "    \n",
    "    scores.append(score)\n",
    "    print(f\"Partie {episode+1}/10 : Score = {score}\")\n",
    "\n",
    "print(f\"\\nüìä Score moyen sur 10 parties : {sum(scores)/len(scores):.1f}\")\n",
    "print(f\"   Meilleur score : {max(scores)}\")\n",
    "print(f\"   Pire score : {min(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aaaaa9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Notes\n",
    "\n",
    "### Pour utiliser le mod√®le en local :\n",
    "\n",
    "1. T√©l√©chargez le fichier `.zip` du mod√®le\n",
    "2. Placez-le dans `checkpoints/PPO_CNN/` de votre projet local\n",
    "3. Lancez `python test_play_cnn.py`\n",
    "\n",
    "### Pour am√©liorer les r√©sultats :\n",
    "\n",
    "- Augmentez `TIMESTEPS` (5M, 10M...)\n",
    "- Ajustez `learning_rate` (0.0001, 0.00003...)\n",
    "- Modifiez les r√©compenses dans l'environnement\n",
    "- Ajoutez des r√©compenses interm√©diaires (se rapprocher de la pomme)\n",
    "\n",
    "---\n",
    "\n",
    "**Auteur** : Samy EH - Projet SY23 - Janvier 2026"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
